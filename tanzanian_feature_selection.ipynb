{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wrangle import note, low_occurance\n",
    "import category_encoders as ce\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>num_private</th>\n",
       "      <th>...</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69572</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>2011-03-14</td>\n",
       "      <td>Roman</td>\n",
       "      <td>1390</td>\n",
       "      <td>Roman</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-03-06</td>\n",
       "      <td>Grumeti</td>\n",
       "      <td>1399</td>\n",
       "      <td>GRUMETI</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>Zahanati</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34310</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2013-02-25</td>\n",
       "      <td>Lottery Club</td>\n",
       "      <td>686</td>\n",
       "      <td>World vision</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>Kwa Mahundi</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>dam</td>\n",
       "      <td>dam</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-28</td>\n",
       "      <td>Unicef</td>\n",
       "      <td>263</td>\n",
       "      <td>UNICEF</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>small_fry</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>dry</td>\n",
       "      <td>dry</td>\n",
       "      <td>machine dbh</td>\n",
       "      <td>borehole</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-07-13</td>\n",
       "      <td>small_fry</td>\n",
       "      <td>0</td>\n",
       "      <td>Artisan</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>Shuleni</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  amount_tsh date_recorded        funder  gps_height     installer  \\\n",
       "0  69572      6000.0    2011-03-14         Roman        1390         Roman   \n",
       "1   8776         0.0    2013-03-06       Grumeti        1399       GRUMETI   \n",
       "2  34310        25.0    2013-02-25  Lottery Club         686  World vision   \n",
       "3  67743         0.0    2013-01-28        Unicef         263        UNICEF   \n",
       "4  19728         0.0    2011-07-13     small_fry           0       Artisan   \n",
       "\n",
       "   longitude   latitude     wpt_name  num_private  ... water_quality  \\\n",
       "0  34.938093  -9.856322         none            0  ...          soft   \n",
       "1  34.698766  -2.147466     Zahanati            0  ...          soft   \n",
       "2  37.460664  -3.821329  Kwa Mahundi            0  ...          soft   \n",
       "3  38.486161 -11.155298    small_fry            0  ...          soft   \n",
       "4  31.130847  -1.825359      Shuleni            0  ...          soft   \n",
       "\n",
       "  quality_group      quantity  quantity_group                source  \\\n",
       "0          good        enough          enough                spring   \n",
       "1          good  insufficient    insufficient  rainwater harvesting   \n",
       "2          good        enough          enough                   dam   \n",
       "3          good           dry             dry           machine dbh   \n",
       "4          good      seasonal        seasonal  rainwater harvesting   \n",
       "\n",
       "            source_type source_class              waterpoint_type  \\\n",
       "0                spring  groundwater           communal standpipe   \n",
       "1  rainwater harvesting      surface           communal standpipe   \n",
       "2                   dam      surface  communal standpipe multiple   \n",
       "3              borehole  groundwater  communal standpipe multiple   \n",
       "4  rainwater harvesting      surface           communal standpipe   \n",
       "\n",
       "  waterpoint_type_group    status_group  \n",
       "0    communal standpipe      functional  \n",
       "1    communal standpipe      functional  \n",
       "2    communal standpipe      functional  \n",
       "3    communal standpipe  non functional  \n",
       "4    communal standpipe      functional  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data         = pd.read_csv('train_features.csv')\n",
    "feature_info = pd.read_csv('train_labels.csv')\n",
    "\n",
    "feature_info = feature_info.drop(columns = 'id')\n",
    "\n",
    "data = low_occurance(note(pd.concat([data, feature_info], \n",
    "                                    sort = False, axis = 1)))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finish_dataframe (data=data):\n",
    "    \n",
    "    df = data[['latitude','longitude','gps_height','population','ward',\n",
    "               'construction_year','amount_tsh','quantity','funder',\n",
    "               'waterpoint_type', 'status_group','extraction_type',\n",
    "               'source','management']]\n",
    "\n",
    "    df['longitude'] = df['longitude'].replace(0 ,np.nan)\n",
    "    df['latitude'] = df['latitude'].replace(-2.000000e-08 ,np.nan)\n",
    "\n",
    "    df = df.dropna()\n",
    "    \n",
    "\n",
    "    n_clusters = [50, 6000]\n",
    "\n",
    "    for n in n_clusters:\n",
    "        kmeans = KMeans(n_clusters=n, n_jobs=-1)\n",
    "        kmeans.fit(df[['longitude','latitude']])\n",
    "        y_kmeans = kmeans.predict(df[['longitude','latitude']])\n",
    "\n",
    "        df[str(n)+'_kmeans_clusters'] = y_kmeans\n",
    "\n",
    "    df = df.drop(columns=['latitude','longitude'])\n",
    "    \n",
    "    ordinal = ce.OrdinalEncoder(return_df=True)\n",
    "    df = ordinal.fit_transform(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = finish_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=10000, multi_class='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  10 | elapsed:  2.5min remaining:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:  2.8min remaining:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:  3.1min remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  3.9min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = df.drop(columns='status_group')\n",
    "y = df['status_group']\n",
    "\n",
    "model.fit(X , y)\n",
    "\n",
    "score  = (cross_val_score(model, X, y, \n",
    "                          cv = 10, \n",
    "                          scoring = 'accuracy',\n",
    "                          n_jobs = -1,\n",
    "                          verbose = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Spread:  [0.63579103 0.63764357 0.63208596 0.63016491 0.63572355 0.6386212\n",
      " 0.63843588 0.62861379 0.64003707 0.63410565]\n",
      "Cross Validation Mean:  0.6351222611775732\n",
      "Cross Validation STDV:  0.0036294907152368524\n"
     ]
    }
   ],
   "source": [
    "print('Cross Validation Spread: ', score)\n",
    "print('Cross Validation Mean: ', score.mean())\n",
    "print('Cross Validation STDV: ', np.std(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgbc = XGBClassifier(booster='gbtree', colsample_bylevel=1, colsample_bytree=1, max_delta_step=0, \n",
    "                     max_depth=17, min_child_weight=1, missing=None, n_estimators=100, n_jobs=-1, \n",
    "                     objective='multi:softmax',num_class=3,andom_state=42, reg_alpha=0, reg_lambda=1, \n",
    "                     scale_pos_weight=1,seed=42, silent=True, subsample=1, eval_metric='merror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 25.1min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 29.2min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed: 33.5min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 49.6min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed: 58.6min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed: 65.4min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed: 79.8min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed: 87.1min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed: 108.4min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 129.0min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed: 146.2min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 169.6min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed: 188.3min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed: 199.1min\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed: 227.4min\n",
      "[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed: 251.2min\n",
      "[Parallel(n_jobs=-1)]: Done 297 tasks      | elapsed: 290.1min\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed: 316.5min\n",
      "[Parallel(n_jobs=-1)]: Done 349 tasks      | elapsed: 356.0min\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed: 391.4min\n",
      "[Parallel(n_jobs=-1)]: Done 405 tasks      | elapsed: 418.1min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 445.7min\n",
      "[Parallel(n_jobs=-1)]: Done 465 tasks      | elapsed: 483.7min\n",
      "[Parallel(n_jobs=-1)]: Done 496 tasks      | elapsed: 510.8min\n",
      "[Parallel(n_jobs=-1)]: Done 529 tasks      | elapsed: 552.7min\n",
      "[Parallel(n_jobs=-1)]: Done 562 tasks      | elapsed: 593.9min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed: 643.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=XGBClassifier(andom_state=42, base_score=0.5,\n",
       "                                           booster='gbtree',\n",
       "                                           colsample_bylevel=1,\n",
       "                                           colsample_bynode=1,\n",
       "                                           colsample_bytree=1,\n",
       "                                           eval_metric='merror', gamma=0,\n",
       "                                           learning_rate=0.1, max_delta_step=0,\n",
       "                                           max_depth=17, min_child_weight=1,\n",
       "                                           missing=None, n_estimators=100,\n",
       "                                           n_jobs=-1, nthread=None, num_class=3,\n",
       "                                           obje...\n",
       "       427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
       "       440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452,\n",
       "       453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465,\n",
       "       466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478,\n",
       "       479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491,\n",
       "       492, 493, 494, 495, 496, 497, 498, 499])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=True, scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distributions = {\n",
    "    'base_score': np.arange(start=0.3, stop=0.72, step=0.02),\n",
    "    'max_depth': np.arange(start=1, stop=100),\n",
    "    'n_estimators': np.arange(start=50, stop=500),\n",
    "}\n",
    "\n",
    "RSCV = RandomizedSearchCV(estimator=xgbc, \n",
    "                          param_distributions=param_distributions, \n",
    "                          n_iter=120, \n",
    "                          scoring='accuracy', \n",
    "                          n_jobs=-1, \n",
    "                          cv=5, \n",
    "                          verbose=10, \n",
    "                          random_state=42, \n",
    "                          return_train_score=True)\n",
    "\n",
    "X = df.drop(columns='status_group')\n",
    "y = df['status_group']\n",
    "\n",
    "RSCV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_base_score</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>179.836953</td>\n",
       "      <td>4.776229</td>\n",
       "      <td>7.239346</td>\n",
       "      <td>0.837258</td>\n",
       "      <td>439</td>\n",
       "      <td>9</td>\n",
       "      <td>0.66</td>\n",
       "      <td>{'n_estimators': 439, 'max_depth': 9, 'base_sc...</td>\n",
       "      <td>0.810080</td>\n",
       "      <td>0.807671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808194</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.939868</td>\n",
       "      <td>0.944107</td>\n",
       "      <td>0.942602</td>\n",
       "      <td>0.944504</td>\n",
       "      <td>0.946148</td>\n",
       "      <td>0.943446</td>\n",
       "      <td>0.002115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>108.149912</td>\n",
       "      <td>4.663385</td>\n",
       "      <td>3.708100</td>\n",
       "      <td>0.419618</td>\n",
       "      <td>165</td>\n",
       "      <td>13</td>\n",
       "      <td>0.62</td>\n",
       "      <td>{'n_estimators': 165, 'max_depth': 13, 'base_s...</td>\n",
       "      <td>0.809802</td>\n",
       "      <td>0.802853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805878</td>\n",
       "      <td>0.002919</td>\n",
       "      <td>2</td>\n",
       "      <td>0.958839</td>\n",
       "      <td>0.960067</td>\n",
       "      <td>0.961318</td>\n",
       "      <td>0.959374</td>\n",
       "      <td>0.962454</td>\n",
       "      <td>0.960410</td>\n",
       "      <td>0.001316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>99.125538</td>\n",
       "      <td>5.093529</td>\n",
       "      <td>3.532050</td>\n",
       "      <td>0.588358</td>\n",
       "      <td>142</td>\n",
       "      <td>14</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'n_estimators': 142, 'max_depth': 14, 'base_s...</td>\n",
       "      <td>0.809802</td>\n",
       "      <td>0.802390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805433</td>\n",
       "      <td>0.003151</td>\n",
       "      <td>3</td>\n",
       "      <td>0.964861</td>\n",
       "      <td>0.963935</td>\n",
       "      <td>0.965116</td>\n",
       "      <td>0.963705</td>\n",
       "      <td>0.966345</td>\n",
       "      <td>0.964793</td>\n",
       "      <td>0.000942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>46.376212</td>\n",
       "      <td>0.366455</td>\n",
       "      <td>1.080350</td>\n",
       "      <td>0.089693</td>\n",
       "      <td>86</td>\n",
       "      <td>11</td>\n",
       "      <td>0.42</td>\n",
       "      <td>{'n_estimators': 86, 'max_depth': 11, 'base_sc...</td>\n",
       "      <td>0.807022</td>\n",
       "      <td>0.801927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.804951</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>4</td>\n",
       "      <td>0.904823</td>\n",
       "      <td>0.907787</td>\n",
       "      <td>0.908204</td>\n",
       "      <td>0.905846</td>\n",
       "      <td>0.911220</td>\n",
       "      <td>0.907576</td>\n",
       "      <td>0.002204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>55.441087</td>\n",
       "      <td>1.074257</td>\n",
       "      <td>0.971262</td>\n",
       "      <td>0.046881</td>\n",
       "      <td>137</td>\n",
       "      <td>9</td>\n",
       "      <td>0.36</td>\n",
       "      <td>{'n_estimators': 137, 'max_depth': 9, 'base_sc...</td>\n",
       "      <td>0.804614</td>\n",
       "      <td>0.803224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.803654</td>\n",
       "      <td>0.003335</td>\n",
       "      <td>5</td>\n",
       "      <td>0.882401</td>\n",
       "      <td>0.886639</td>\n",
       "      <td>0.883906</td>\n",
       "      <td>0.882035</td>\n",
       "      <td>0.888938</td>\n",
       "      <td>0.884784</td>\n",
       "      <td>0.002634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "86     179.836953      4.776229         7.239346        0.837258   \n",
       "22     108.149912      4.663385         3.708100        0.419618   \n",
       "80      99.125538      5.093529         3.532050        0.588358   \n",
       "93      46.376212      0.366455         1.080350        0.089693   \n",
       "9       55.441087      1.074257         0.971262        0.046881   \n",
       "\n",
       "   param_n_estimators param_max_depth param_base_score  \\\n",
       "86                439               9             0.66   \n",
       "22                165              13             0.62   \n",
       "80                142              14              0.7   \n",
       "93                 86              11             0.42   \n",
       "9                 137               9             0.36   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "86  {'n_estimators': 439, 'max_depth': 9, 'base_sc...           0.810080   \n",
       "22  {'n_estimators': 165, 'max_depth': 13, 'base_s...           0.809802   \n",
       "80  {'n_estimators': 142, 'max_depth': 14, 'base_s...           0.809802   \n",
       "93  {'n_estimators': 86, 'max_depth': 11, 'base_sc...           0.807022   \n",
       "9   {'n_estimators': 137, 'max_depth': 9, 'base_sc...           0.804614   \n",
       "\n",
       "    split1_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "86           0.807671  ...         0.808194        0.003300                1   \n",
       "22           0.802853  ...         0.805878        0.002919                2   \n",
       "80           0.802390  ...         0.805433        0.003151                3   \n",
       "93           0.801927  ...         0.804951        0.002914                4   \n",
       "9            0.803224  ...         0.803654        0.003335                5   \n",
       "\n",
       "    split0_train_score  split1_train_score  split2_train_score  \\\n",
       "86            0.939868            0.944107            0.942602   \n",
       "22            0.958839            0.960067            0.961318   \n",
       "80            0.964861            0.963935            0.965116   \n",
       "93            0.904823            0.907787            0.908204   \n",
       "9             0.882401            0.886639            0.883906   \n",
       "\n",
       "    split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "86            0.944504            0.946148          0.943446         0.002115  \n",
       "22            0.959374            0.962454          0.960410         0.001316  \n",
       "80            0.963705            0.966345          0.964793         0.000942  \n",
       "93            0.905846            0.911220          0.907576         0.002204  \n",
       "9             0.882035            0.888938          0.884784         0.002634  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_RSCV = pd.DataFrame(RSCV.cv_results_)\n",
    "results_RSCV.sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(andom_state=42, base_score=0.6600000000000004, booster='gbtree',\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              eval_metric='merror', gamma=0, learning_rate=0.1,\n",
       "              max_delta_step=0, max_depth=9, min_child_weight=1, missing=None,\n",
       "              n_estimators=439, n_jobs=-1, nthread=None, num_class=3,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "              subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RSCV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 10.9min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed: 17.5min\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed: 19.8min\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed: 22.0min\n",
      "[Parallel(n_jobs=-1)]: Done 129 tasks      | elapsed: 24.8min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 27.8min\n",
      "[Parallel(n_jobs=-1)]: Done 165 tasks      | elapsed: 32.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 35.2min\n",
      "[Parallel(n_jobs=-1)]: Done 205 tasks      | elapsed: 37.8min\n",
      "[Parallel(n_jobs=-1)]: Done 226 tasks      | elapsed: 41.2min\n",
      "[Parallel(n_jobs=-1)]: Done 249 tasks      | elapsed: 45.2min\n",
      "[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed: 48.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(andom_state=42, base_score=0.5,\n",
       "                                     booster='gbtree', colsample_bylevel=1,\n",
       "                                     colsample_bynode=1, colsample_bytree=1,\n",
       "                                     eval_metric='merror', gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=17, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=-1,\n",
       "                                     nthread=None, num_class=3,\n",
       "                                     objective='multi:softmax', random_state=0,\n",
       "                                     reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=42, silent=True,\n",
       "                                     subsample=1, verbosity=1),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'base_score': [0.65], 'gamma': [0, 1, 5],\n",
       "                         'max_depth': [9, 10, 11, 12, 13, 14],\n",
       "                         'n_estimators': [137, 142, 165]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_distributions = {\n",
    "    'base_score': [0.65],\n",
    "    'max_depth': [9,10,11,12,13,14],\n",
    "    'gamma': [0,1,5],\n",
    "    'n_estimators': [137, 142, 165]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "GSCV = GridSearchCV(estimator=xgbc, \n",
    "                    param_grid=param_distributions, \n",
    "                    scoring='accuracy', \n",
    "                    n_jobs=-1,\n",
    "                    refit=True, \n",
    "                    cv=5, \n",
    "                    verbose=10, \n",
    "                    return_train_score=True)\n",
    "\n",
    "X = df.drop(columns='status_group')\n",
    "y = df['status_group']\n",
    "\n",
    "GSCV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_base_score</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>68.512402</td>\n",
       "      <td>0.241346</td>\n",
       "      <td>1.460493</td>\n",
       "      <td>0.216840</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>137</td>\n",
       "      <td>{'base_score': 0.65, 'gamma': 1, 'max_depth': ...</td>\n",
       "      <td>0.812859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808250</td>\n",
       "      <td>0.003376</td>\n",
       "      <td>1</td>\n",
       "      <td>0.902553</td>\n",
       "      <td>0.902900</td>\n",
       "      <td>0.902205</td>\n",
       "      <td>0.900380</td>\n",
       "      <td>0.905916</td>\n",
       "      <td>0.902791</td>\n",
       "      <td>0.001788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>70.583746</td>\n",
       "      <td>0.380141</td>\n",
       "      <td>1.429504</td>\n",
       "      <td>0.121961</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>142</td>\n",
       "      <td>{'base_score': 0.65, 'gamma': 1, 'max_depth': ...</td>\n",
       "      <td>0.812581</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808138</td>\n",
       "      <td>0.003369</td>\n",
       "      <td>2</td>\n",
       "      <td>0.903085</td>\n",
       "      <td>0.903062</td>\n",
       "      <td>0.902761</td>\n",
       "      <td>0.900959</td>\n",
       "      <td>0.906541</td>\n",
       "      <td>0.903282</td>\n",
       "      <td>0.001810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>80.888325</td>\n",
       "      <td>0.513623</td>\n",
       "      <td>1.650179</td>\n",
       "      <td>0.293211</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>165</td>\n",
       "      <td>{'base_score': 0.65, 'gamma': 1, 'max_depth': ...</td>\n",
       "      <td>0.811469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807935</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>3</td>\n",
       "      <td>0.906861</td>\n",
       "      <td>0.905425</td>\n",
       "      <td>0.906652</td>\n",
       "      <td>0.903599</td>\n",
       "      <td>0.909112</td>\n",
       "      <td>0.906330</td>\n",
       "      <td>0.001811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>77.845087</td>\n",
       "      <td>1.459640</td>\n",
       "      <td>2.927861</td>\n",
       "      <td>0.560442</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>142</td>\n",
       "      <td>{'base_score': 0.65, 'gamma': 0, 'max_depth': ...</td>\n",
       "      <td>0.811562</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807768</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>4</td>\n",
       "      <td>0.943227</td>\n",
       "      <td>0.944154</td>\n",
       "      <td>0.945543</td>\n",
       "      <td>0.942952</td>\n",
       "      <td>0.945013</td>\n",
       "      <td>0.944178</td>\n",
       "      <td>0.000997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>77.031683</td>\n",
       "      <td>2.508786</td>\n",
       "      <td>2.601822</td>\n",
       "      <td>0.668278</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>137</td>\n",
       "      <td>{'base_score': 0.65, 'gamma': 0, 'max_depth': ...</td>\n",
       "      <td>0.810636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807749</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>5</td>\n",
       "      <td>0.941837</td>\n",
       "      <td>0.942231</td>\n",
       "      <td>0.944200</td>\n",
       "      <td>0.941632</td>\n",
       "      <td>0.943322</td>\n",
       "      <td>0.942644</td>\n",
       "      <td>0.000972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "24      68.512402      0.241346         1.460493        0.216840   \n",
       "25      70.583746      0.380141         1.429504        0.121961   \n",
       "26      80.888325      0.513623         1.650179        0.293211   \n",
       "10      77.845087      1.459640         2.927861        0.560442   \n",
       "9       77.031683      2.508786         2.601822        0.668278   \n",
       "\n",
       "   param_base_score param_gamma param_max_depth param_n_estimators  \\\n",
       "24             0.65           1              11                137   \n",
       "25             0.65           1              11                142   \n",
       "26             0.65           1              11                165   \n",
       "10             0.65           0              12                142   \n",
       "9              0.65           0              12                137   \n",
       "\n",
       "                                               params  split0_test_score  ...  \\\n",
       "24  {'base_score': 0.65, 'gamma': 1, 'max_depth': ...           0.812859  ...   \n",
       "25  {'base_score': 0.65, 'gamma': 1, 'max_depth': ...           0.812581  ...   \n",
       "26  {'base_score': 0.65, 'gamma': 1, 'max_depth': ...           0.811469  ...   \n",
       "10  {'base_score': 0.65, 'gamma': 0, 'max_depth': ...           0.811562  ...   \n",
       "9   {'base_score': 0.65, 'gamma': 0, 'max_depth': ...           0.810636  ...   \n",
       "\n",
       "    mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "24         0.808250        0.003376                1            0.902553   \n",
       "25         0.808138        0.003369                2            0.903085   \n",
       "26         0.807935        0.002428                3            0.906861   \n",
       "10         0.807768        0.003162                4            0.943227   \n",
       "9          0.807749        0.003081                5            0.941837   \n",
       "\n",
       "    split1_train_score  split2_train_score  split3_train_score  \\\n",
       "24            0.902900            0.902205            0.900380   \n",
       "25            0.903062            0.902761            0.900959   \n",
       "26            0.905425            0.906652            0.903599   \n",
       "10            0.944154            0.945543            0.942952   \n",
       "9             0.942231            0.944200            0.941632   \n",
       "\n",
       "    split4_train_score  mean_train_score  std_train_score  \n",
       "24            0.905916          0.902791         0.001788  \n",
       "25            0.906541          0.903282         0.001810  \n",
       "26            0.909112          0.906330         0.001811  \n",
       "10            0.945013          0.944178         0.000997  \n",
       "9             0.943322          0.942644         0.000972  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_GSCV = pd.DataFrame(GSCV.cv_results_)\n",
    "results_GSCV.sort_values(by='rank_test_score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. , 2.2, 2.4,\n",
       "       2.6, 2.8, 3. , 3.2, 3.4, 3.6, 3.8, 4. , 4.2, 4.4, 4.6, 4.8])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(start=0, stop=5, step=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  30 | elapsed: 16.0min remaining:  9.3min\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed: 19.5min remaining:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed: 22.4min remaining:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 28.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   52.8s\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  30 | elapsed:  1.6min remaining:   56.6s\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed:  2.8min remaining:   51.5s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:  3.9min remaining:   25.8s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  5.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  30 | elapsed: 23.3min remaining: 13.5min\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed: 27.0min remaining:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed: 29.1min remaining:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 29.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  30 | elapsed: 15.4min remaining:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done  23 out of  30 | elapsed: 20.4min remaining:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed: 21.2min remaining:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed: 22.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=3, error_score='raise',\n",
       "       estimator=XGBClassifier(andom_state=42, base_score=0.5, booster='gbtree',\n",
       "       colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "       eval_metric='merror', gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=17, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=-1, nthread=None, num_class=3, objective='multi:softmax',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=42, silent=True, subsample=1, verbosity=1),\n",
       "       fit_params=None, iid=True, n_iter=40, n_jobs=-1, n_points=10,\n",
       "       optimizer_kwargs=None, pre_dispatch='2*n_jobs', random_state=42,\n",
       "       refit=True, return_train_score=True, scoring='accuracy',\n",
       "       search_spaces={'base_score': (0.3, 0.7), 'max_depth': (1, 100), 'n_estimators': (50, 500), 'gamma': (0, 5), 'learning_rate': (0.01, 0.3)},\n",
       "       verbose=10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "\n",
    "X = df.drop(columns='status_group')\n",
    "y = df['status_group']\n",
    "\n",
    "param_grid = {\n",
    "    'base_score': (0.3, 0.7),\n",
    "    'max_depth': (1, 100),\n",
    "    'n_estimators': (50, 500),\n",
    "    'gamma': (0, 5),\n",
    "    'learning_rate': (0.01, 0.3)\n",
    "}\n",
    "\n",
    "BSCV = BayesSearchCV (estimator=xgbc, \n",
    "                      search_spaces=param_grid, \n",
    "                      optimizer_kwargs=None,\n",
    "                      n_iter=40, \n",
    "                      scoring='accuracy', \n",
    "                      fit_params=None, \n",
    "                      n_jobs=-1,\n",
    "                      n_points=10,\n",
    "                      cv=3, \n",
    "                      verbose=10,\n",
    "                      random_state=42,\n",
    "                      return_train_score=True)\n",
    "    \n",
    "BSCV.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "derp = pd.DataFrame(BSCV.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_base_score</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.799044</td>\n",
       "      <td>0.804770</td>\n",
       "      <td>0.799533</td>\n",
       "      <td>0.801116</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>1</td>\n",
       "      <td>0.934236</td>\n",
       "      <td>0.935236</td>\n",
       "      <td>0.934793</td>\n",
       "      <td>0.934755</td>\n",
       "      <td>...</td>\n",
       "      <td>339.056964</td>\n",
       "      <td>1.817613</td>\n",
       "      <td>20.713698</td>\n",
       "      <td>1.434731</td>\n",
       "      <td>0.465647</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>31</td>\n",
       "      <td>341</td>\n",
       "      <td>{'base_score': 0.4656474529942154, 'gamma': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.800767</td>\n",
       "      <td>0.804603</td>\n",
       "      <td>0.799144</td>\n",
       "      <td>0.801505</td>\n",
       "      <td>0.002289</td>\n",
       "      <td>1</td>\n",
       "      <td>0.929372</td>\n",
       "      <td>0.930150</td>\n",
       "      <td>0.930624</td>\n",
       "      <td>0.930049</td>\n",
       "      <td>...</td>\n",
       "      <td>301.375444</td>\n",
       "      <td>0.488189</td>\n",
       "      <td>18.720457</td>\n",
       "      <td>0.258600</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>19</td>\n",
       "      <td>373</td>\n",
       "      <td>{'base_score': 0.3, 'gamma': 1, 'learning_rate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.799544</td>\n",
       "      <td>0.803713</td>\n",
       "      <td>0.798088</td>\n",
       "      <td>0.800448</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>2</td>\n",
       "      <td>0.931206</td>\n",
       "      <td>0.932040</td>\n",
       "      <td>0.931152</td>\n",
       "      <td>0.931466</td>\n",
       "      <td>...</td>\n",
       "      <td>285.210791</td>\n",
       "      <td>3.362891</td>\n",
       "      <td>14.540409</td>\n",
       "      <td>0.590180</td>\n",
       "      <td>0.582179</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>49</td>\n",
       "      <td>289</td>\n",
       "      <td>{'base_score': 0.5821792788079154, 'gamma': 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.800656</td>\n",
       "      <td>0.804269</td>\n",
       "      <td>0.797865</td>\n",
       "      <td>0.800930</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>2</td>\n",
       "      <td>0.926342</td>\n",
       "      <td>0.927009</td>\n",
       "      <td>0.927317</td>\n",
       "      <td>0.926889</td>\n",
       "      <td>...</td>\n",
       "      <td>250.886274</td>\n",
       "      <td>4.732437</td>\n",
       "      <td>14.010658</td>\n",
       "      <td>0.419361</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>19</td>\n",
       "      <td>308</td>\n",
       "      <td>{'base_score': 0.3, 'gamma': 1, 'learning_rate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.797487</td>\n",
       "      <td>0.800823</td>\n",
       "      <td>0.797865</td>\n",
       "      <td>0.798725</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>3</td>\n",
       "      <td>0.860022</td>\n",
       "      <td>0.859799</td>\n",
       "      <td>0.862388</td>\n",
       "      <td>0.860736</td>\n",
       "      <td>...</td>\n",
       "      <td>355.507468</td>\n",
       "      <td>5.443322</td>\n",
       "      <td>21.275508</td>\n",
       "      <td>1.721243</td>\n",
       "      <td>0.464042</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>32</td>\n",
       "      <td>351</td>\n",
       "      <td>{'base_score': 0.4640415835413255, 'gamma': 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.799655</td>\n",
       "      <td>0.802824</td>\n",
       "      <td>0.797198</td>\n",
       "      <td>0.799893</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>3</td>\n",
       "      <td>0.920477</td>\n",
       "      <td>0.921728</td>\n",
       "      <td>0.921535</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>...</td>\n",
       "      <td>200.979956</td>\n",
       "      <td>0.478130</td>\n",
       "      <td>12.037283</td>\n",
       "      <td>1.745370</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>19</td>\n",
       "      <td>227</td>\n",
       "      <td>{'base_score': 0.3, 'gamma': 1, 'learning_rate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.799655</td>\n",
       "      <td>0.802824</td>\n",
       "      <td>0.797198</td>\n",
       "      <td>0.799893</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>3</td>\n",
       "      <td>0.920477</td>\n",
       "      <td>0.921728</td>\n",
       "      <td>0.921535</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>...</td>\n",
       "      <td>216.767523</td>\n",
       "      <td>9.466301</td>\n",
       "      <td>14.068042</td>\n",
       "      <td>2.567897</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>19</td>\n",
       "      <td>227</td>\n",
       "      <td>{'base_score': 0.3, 'gamma': 1, 'learning_rate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.799655</td>\n",
       "      <td>0.802824</td>\n",
       "      <td>0.797198</td>\n",
       "      <td>0.799893</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>3</td>\n",
       "      <td>0.920477</td>\n",
       "      <td>0.921728</td>\n",
       "      <td>0.921535</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>...</td>\n",
       "      <td>201.897935</td>\n",
       "      <td>4.391327</td>\n",
       "      <td>16.506685</td>\n",
       "      <td>2.034995</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>19</td>\n",
       "      <td>227</td>\n",
       "      <td>{'base_score': 0.3, 'gamma': 1, 'learning_rate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.799655</td>\n",
       "      <td>0.802824</td>\n",
       "      <td>0.797198</td>\n",
       "      <td>0.799893</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>3</td>\n",
       "      <td>0.920477</td>\n",
       "      <td>0.921728</td>\n",
       "      <td>0.921535</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>...</td>\n",
       "      <td>187.371574</td>\n",
       "      <td>5.406776</td>\n",
       "      <td>13.491356</td>\n",
       "      <td>0.280905</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>19</td>\n",
       "      <td>227</td>\n",
       "      <td>{'base_score': 0.3, 'gamma': 1, 'learning_rate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.799655</td>\n",
       "      <td>0.802824</td>\n",
       "      <td>0.797198</td>\n",
       "      <td>0.799893</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>3</td>\n",
       "      <td>0.920477</td>\n",
       "      <td>0.921728</td>\n",
       "      <td>0.921535</td>\n",
       "      <td>0.921247</td>\n",
       "      <td>...</td>\n",
       "      <td>180.827302</td>\n",
       "      <td>0.332009</td>\n",
       "      <td>11.423305</td>\n",
       "      <td>0.114447</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>19</td>\n",
       "      <td>227</td>\n",
       "      <td>{'base_score': 0.3, 'gamma': 1, 'learning_rate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.795986</td>\n",
       "      <td>0.796431</td>\n",
       "      <td>0.795308</td>\n",
       "      <td>0.795909</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>4</td>\n",
       "      <td>0.968786</td>\n",
       "      <td>0.969814</td>\n",
       "      <td>0.971121</td>\n",
       "      <td>0.969907</td>\n",
       "      <td>...</td>\n",
       "      <td>304.680244</td>\n",
       "      <td>1.094386</td>\n",
       "      <td>24.545621</td>\n",
       "      <td>1.149699</td>\n",
       "      <td>0.426327</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>19</td>\n",
       "      <td>389</td>\n",
       "      <td>{'base_score': 0.4263270061273533, 'gamma': 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.793596</td>\n",
       "      <td>0.797209</td>\n",
       "      <td>0.795475</td>\n",
       "      <td>0.795427</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>5</td>\n",
       "      <td>0.844456</td>\n",
       "      <td>0.844651</td>\n",
       "      <td>0.847685</td>\n",
       "      <td>0.845597</td>\n",
       "      <td>...</td>\n",
       "      <td>193.546181</td>\n",
       "      <td>6.925339</td>\n",
       "      <td>9.338727</td>\n",
       "      <td>0.800452</td>\n",
       "      <td>0.682213</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>14</td>\n",
       "      <td>314</td>\n",
       "      <td>{'base_score': 0.6822126559627715, 'gamma': 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.792595</td>\n",
       "      <td>0.793874</td>\n",
       "      <td>0.794307</td>\n",
       "      <td>0.793592</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>6</td>\n",
       "      <td>0.971954</td>\n",
       "      <td>0.972788</td>\n",
       "      <td>0.973595</td>\n",
       "      <td>0.972779</td>\n",
       "      <td>...</td>\n",
       "      <td>326.567880</td>\n",
       "      <td>6.195166</td>\n",
       "      <td>20.350426</td>\n",
       "      <td>0.694093</td>\n",
       "      <td>0.411390</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>56</td>\n",
       "      <td>328</td>\n",
       "      <td>{'base_score': 0.4113898428546752, 'gamma': 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.792707</td>\n",
       "      <td>0.793596</td>\n",
       "      <td>0.794307</td>\n",
       "      <td>0.793537</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>7</td>\n",
       "      <td>0.975040</td>\n",
       "      <td>0.976318</td>\n",
       "      <td>0.976652</td>\n",
       "      <td>0.976003</td>\n",
       "      <td>...</td>\n",
       "      <td>372.638954</td>\n",
       "      <td>3.447175</td>\n",
       "      <td>27.131199</td>\n",
       "      <td>5.807056</td>\n",
       "      <td>0.309570</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>91</td>\n",
       "      <td>394</td>\n",
       "      <td>{'base_score': 0.30957012868277645, 'gamma': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.791873</td>\n",
       "      <td>0.790705</td>\n",
       "      <td>0.791027</td>\n",
       "      <td>0.791202</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>8</td>\n",
       "      <td>0.955777</td>\n",
       "      <td>0.956556</td>\n",
       "      <td>0.956918</td>\n",
       "      <td>0.956417</td>\n",
       "      <td>...</td>\n",
       "      <td>178.966886</td>\n",
       "      <td>20.160179</td>\n",
       "      <td>8.124730</td>\n",
       "      <td>0.125518</td>\n",
       "      <td>0.482947</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>71</td>\n",
       "      <td>161</td>\n",
       "      <td>{'base_score': 0.48294711271712754, 'gamma': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.710601</td>\n",
       "      <td>0.718606</td>\n",
       "      <td>0.719758</td>\n",
       "      <td>0.716321</td>\n",
       "      <td>0.004072</td>\n",
       "      <td>8</td>\n",
       "      <td>0.718376</td>\n",
       "      <td>0.716597</td>\n",
       "      <td>0.714631</td>\n",
       "      <td>0.716535</td>\n",
       "      <td>...</td>\n",
       "      <td>24.379245</td>\n",
       "      <td>0.214445</td>\n",
       "      <td>0.353857</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>{'base_score': 0.3, 'gamma': 1, 'learning_rate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.788927</td>\n",
       "      <td>0.787203</td>\n",
       "      <td>0.786135</td>\n",
       "      <td>0.787422</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>9</td>\n",
       "      <td>0.942547</td>\n",
       "      <td>0.941157</td>\n",
       "      <td>0.941297</td>\n",
       "      <td>0.941667</td>\n",
       "      <td>...</td>\n",
       "      <td>80.900365</td>\n",
       "      <td>3.085852</td>\n",
       "      <td>3.939326</td>\n",
       "      <td>0.263553</td>\n",
       "      <td>0.519986</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>63</td>\n",
       "      <td>85</td>\n",
       "      <td>{'base_score': 0.5199855767239137, 'gamma': 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.709156</td>\n",
       "      <td>0.713714</td>\n",
       "      <td>0.716033</td>\n",
       "      <td>0.712967</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>9</td>\n",
       "      <td>0.716180</td>\n",
       "      <td>0.713511</td>\n",
       "      <td>0.709823</td>\n",
       "      <td>0.713171</td>\n",
       "      <td>...</td>\n",
       "      <td>30.604187</td>\n",
       "      <td>0.453300</td>\n",
       "      <td>0.547753</td>\n",
       "      <td>0.019106</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>3</td>\n",
       "      <td>193</td>\n",
       "      <td>{'base_score': 0.3, 'gamma': 1, 'learning_rate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.751237</td>\n",
       "      <td>0.752071</td>\n",
       "      <td>0.758228</td>\n",
       "      <td>0.753845</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>10</td>\n",
       "      <td>0.761514</td>\n",
       "      <td>0.758707</td>\n",
       "      <td>0.759631</td>\n",
       "      <td>0.759951</td>\n",
       "      <td>...</td>\n",
       "      <td>100.874243</td>\n",
       "      <td>0.207244</td>\n",
       "      <td>2.666019</td>\n",
       "      <td>0.025442</td>\n",
       "      <td>0.566732</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>493</td>\n",
       "      <td>{'base_score': 0.56673155880575, 'gamma': 3, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.702485</td>\n",
       "      <td>0.703319</td>\n",
       "      <td>0.707527</td>\n",
       "      <td>0.704444</td>\n",
       "      <td>0.002207</td>\n",
       "      <td>10</td>\n",
       "      <td>0.706896</td>\n",
       "      <td>0.704589</td>\n",
       "      <td>0.706321</td>\n",
       "      <td>0.705935</td>\n",
       "      <td>...</td>\n",
       "      <td>45.747519</td>\n",
       "      <td>0.408600</td>\n",
       "      <td>0.609396</td>\n",
       "      <td>0.020423</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>389</td>\n",
       "      <td>{'base_score': 0.3, 'gamma': 1, 'learning_rate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "1            0.799044           0.804770           0.799533         0.801116   \n",
       "10           0.800767           0.804603           0.799144         0.801505   \n",
       "5            0.799544           0.803713           0.798088         0.800448   \n",
       "12           0.800656           0.804269           0.797865         0.800930   \n",
       "0            0.797487           0.800823           0.797865         0.798725   \n",
       "16           0.799655           0.802824           0.797198         0.799893   \n",
       "15           0.799655           0.802824           0.797198         0.799893   \n",
       "14           0.799655           0.802824           0.797198         0.799893   \n",
       "13           0.799655           0.802824           0.797198         0.799893   \n",
       "11           0.799655           0.802824           0.797198         0.799893   \n",
       "8            0.795986           0.796431           0.795308         0.795909   \n",
       "7            0.793596           0.797209           0.795475         0.795427   \n",
       "6            0.792595           0.793874           0.794307         0.793592   \n",
       "9            0.792707           0.793596           0.794307         0.793537   \n",
       "4            0.791873           0.790705           0.791027         0.791202   \n",
       "17           0.710601           0.718606           0.719758         0.716321   \n",
       "2            0.788927           0.787203           0.786135         0.787422   \n",
       "18           0.709156           0.713714           0.716033         0.712967   \n",
       "3            0.751237           0.752071           0.758228         0.753845   \n",
       "19           0.702485           0.703319           0.707527         0.704444   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "1         0.002592                1            0.934236            0.935236   \n",
       "10        0.002289                1            0.929372            0.930150   \n",
       "5         0.002384                2            0.931206            0.932040   \n",
       "12        0.002622                2            0.926342            0.927009   \n",
       "0         0.001491                3            0.860022            0.859799   \n",
       "16        0.002303                3            0.920477            0.921728   \n",
       "15        0.002303                3            0.920477            0.921728   \n",
       "14        0.002303                3            0.920477            0.921728   \n",
       "13        0.002303                3            0.920477            0.921728   \n",
       "11        0.002303                3            0.920477            0.921728   \n",
       "8         0.000462                4            0.968786            0.969814   \n",
       "7         0.001476                5            0.844456            0.844651   \n",
       "6         0.000727                6            0.971954            0.972788   \n",
       "9         0.000655                7            0.975040            0.976318   \n",
       "4         0.000492                8            0.955777            0.956556   \n",
       "17        0.004072                8            0.718376            0.716597   \n",
       "2         0.001150                9            0.942547            0.941157   \n",
       "18        0.002857                9            0.716180            0.713511   \n",
       "3         0.003118               10            0.761514            0.758707   \n",
       "19        0.002207               10            0.706896            0.704589   \n",
       "\n",
       "    split2_train_score  mean_train_score  ...  mean_fit_time  std_fit_time  \\\n",
       "1             0.934793          0.934755  ...     339.056964      1.817613   \n",
       "10            0.930624          0.930049  ...     301.375444      0.488189   \n",
       "5             0.931152          0.931466  ...     285.210791      3.362891   \n",
       "12            0.927317          0.926889  ...     250.886274      4.732437   \n",
       "0             0.862388          0.860736  ...     355.507468      5.443322   \n",
       "16            0.921535          0.921247  ...     200.979956      0.478130   \n",
       "15            0.921535          0.921247  ...     216.767523      9.466301   \n",
       "14            0.921535          0.921247  ...     201.897935      4.391327   \n",
       "13            0.921535          0.921247  ...     187.371574      5.406776   \n",
       "11            0.921535          0.921247  ...     180.827302      0.332009   \n",
       "8             0.971121          0.969907  ...     304.680244      1.094386   \n",
       "7             0.847685          0.845597  ...     193.546181      6.925339   \n",
       "6             0.973595          0.972779  ...     326.567880      6.195166   \n",
       "9             0.976652          0.976003  ...     372.638954      3.447175   \n",
       "4             0.956918          0.956417  ...     178.966886     20.160179   \n",
       "17            0.714631          0.716535  ...      24.379245      0.214445   \n",
       "2             0.941297          0.941667  ...      80.900365      3.085852   \n",
       "18            0.709823          0.713171  ...      30.604187      0.453300   \n",
       "3             0.759631          0.759951  ...     100.874243      0.207244   \n",
       "19            0.706321          0.705935  ...      45.747519      0.408600   \n",
       "\n",
       "    mean_score_time  std_score_time  param_base_score  param_gamma  \\\n",
       "1         20.713698        1.434731          0.465647            1   \n",
       "10        18.720457        0.258600          0.300000            1   \n",
       "5         14.540409        0.590180          0.582179            1   \n",
       "12        14.010658        0.419361          0.300000            1   \n",
       "0         21.275508        1.721243          0.464042            3   \n",
       "16        12.037283        1.745370          0.300000            1   \n",
       "15        14.068042        2.567897          0.300000            1   \n",
       "14        16.506685        2.034995          0.300000            1   \n",
       "13        13.491356        0.280905          0.300000            1   \n",
       "11        11.423305        0.114447          0.300000            1   \n",
       "8         24.545621        1.149699          0.426327            0   \n",
       "7          9.338727        0.800452          0.682213            3   \n",
       "6         20.350426        0.694093          0.411390            0   \n",
       "9         27.131199        5.807056          0.309570            0   \n",
       "4          8.124730        0.125518          0.482947            0   \n",
       "17         0.353857        0.002615          0.300000            1   \n",
       "2          3.939326        0.263553          0.519986            0   \n",
       "18         0.547753        0.019106          0.300000            1   \n",
       "3          2.666019        0.025442          0.566732            3   \n",
       "19         0.609396        0.020423          0.300000            1   \n",
       "\n",
       "    param_learning_rate  param_max_depth  param_n_estimators  \\\n",
       "1                  0.01               31                 341   \n",
       "10                 0.01               19                 373   \n",
       "5                  0.01               49                 289   \n",
       "12                 0.01               19                 308   \n",
       "0                  0.01               32                 351   \n",
       "16                 0.01               19                 227   \n",
       "15                 0.01               19                 227   \n",
       "14                 0.01               19                 227   \n",
       "13                 0.01               19                 227   \n",
       "11                 0.01               19                 227   \n",
       "8                  0.01               19                 389   \n",
       "7                  0.01               14                 314   \n",
       "6                  0.01               56                 328   \n",
       "9                  0.01               91                 394   \n",
       "4                  0.01               71                 161   \n",
       "17                 0.01                4                 128   \n",
       "2                  0.01               63                  85   \n",
       "18                 0.01                3                 193   \n",
       "3                  0.01                5                 493   \n",
       "19                 0.01                2                 389   \n",
       "\n",
       "                                               params  \n",
       "1   {'base_score': 0.4656474529942154, 'gamma': 1,...  \n",
       "10  {'base_score': 0.3, 'gamma': 1, 'learning_rate...  \n",
       "5   {'base_score': 0.5821792788079154, 'gamma': 1,...  \n",
       "12  {'base_score': 0.3, 'gamma': 1, 'learning_rate...  \n",
       "0   {'base_score': 0.4640415835413255, 'gamma': 3,...  \n",
       "16  {'base_score': 0.3, 'gamma': 1, 'learning_rate...  \n",
       "15  {'base_score': 0.3, 'gamma': 1, 'learning_rate...  \n",
       "14  {'base_score': 0.3, 'gamma': 1, 'learning_rate...  \n",
       "13  {'base_score': 0.3, 'gamma': 1, 'learning_rate...  \n",
       "11  {'base_score': 0.3, 'gamma': 1, 'learning_rate...  \n",
       "8   {'base_score': 0.4263270061273533, 'gamma': 0,...  \n",
       "7   {'base_score': 0.6822126559627715, 'gamma': 3,...  \n",
       "6   {'base_score': 0.4113898428546752, 'gamma': 0,...  \n",
       "9   {'base_score': 0.30957012868277645, 'gamma': 0...  \n",
       "4   {'base_score': 0.48294711271712754, 'gamma': 0...  \n",
       "17  {'base_score': 0.3, 'gamma': 1, 'learning_rate...  \n",
       "2   {'base_score': 0.5199855767239137, 'gamma': 0,...  \n",
       "18  {'base_score': 0.3, 'gamma': 1, 'learning_rate...  \n",
       "3   {'base_score': 0.56673155880575, 'gamma': 3, '...  \n",
       "19  {'base_score': 0.3, 'gamma': 1, 'learning_rate...  \n",
       "\n",
       "[20 rows x 21 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
